{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO I will no longer be updating this project since I'm not using it anymore.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "import json \n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = \"https://housing.uga.edu/explore-options/\"\n",
    "page = requests.get(URL)\n",
    "# exploreHall hosts name \n",
    "#explorePhoto hosts photo \n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hallList = []\n",
    "for item in soup.find_all('div', id='exploreHall'):\n",
    "    item = item.get_text()\n",
    "    item = str(item)\n",
    "    hallList.append(item)\n",
    "\n",
    "\n",
    "# multiple hall names, internal text.\n",
    "URL_INTERNAL = []\n",
    "\n",
    "for i in range(len(hallList)):\n",
    "    URL_INTERNAL.append(\"https://housing.uga.edu/explore-options/\" +\n",
    "                        hallList[i].strip().replace(' ', '-') + \"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#don't touch under, all of these work already.\n",
    "\n",
    "substring = \"/sa_images/featured/\"\n",
    "photoList = []\n",
    "# ,id=\"explorePhoto\"\n",
    "for picture in soup.find_all(\"img\"):\n",
    "    #picture = str(picture)\n",
    "    if substring in str(picture):\n",
    "        picture = picture['src']\n",
    "        photoList.append(picture)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for key in hallList:\n",
    "    for value in photoList:\n",
    "        res[key] = value\n",
    "        photoList.remove(value)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('some.csv', 'w') as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     for key, value in res.items():\n",
    "#        writer.writerow([key, value])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# csvfile = open('some.csv', 'r')\n",
    "# jsonfile = open('file.json', 'w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fieldnames = (\"Name of Hall \", \"Photo of Hall \")\n",
    "# reader = csv.DictReader(csvfile, fieldnames)\n",
    "# for row in reader:\n",
    "#     json.dump(row, jsonfile)\n",
    "#     jsonfile.write('\\n')\n",
    "\n",
    "# jsonfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each key in hallist, go to the link of the hall, and inner information (this is the titles)\n",
    "inner_information = [\"Visitation\", \"Open for Breaks\", \"Bus Stops\", \"Parking Lot\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the ACTUAL information for each hall\n",
    "spans = []\n",
    "\n",
    "for i in range(len(URL_INTERNAL)):\n",
    "    page_inside = requests.get(URL_INTERNAL[i])\n",
    "    soup_inside = BeautifulSoup(page_inside.content, \"html.parser\")\n",
    "    for i in range(len(URL_INTERNAL)):\n",
    "        spans.append(soup_inside.find_all('span', {'class': 'nearby-right'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each value in spans add it to df \n",
    "new = []\n",
    "for i in range(len(spans)):\n",
    "    for j in range(len(spans[i])):\n",
    "        new.insert(j,soup_inside.find_all(\n",
    "            'span', {'class': 'nearby-right'})[j].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=hallList, index=inner_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the dataframe with values from new \n",
    "\n",
    "for i in range(len(new)):\n",
    "    df.loc[i] = new[i]\n",
    "    \n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bcfac60cd316cab1810c67f16d75e14abb874771ecdd5af4e3a00fe11b217a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
